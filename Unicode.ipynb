{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "size = sys.getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'ed henderson\\u1ff0'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ed' + u' henderson\\u1ff0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(basestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(basestring,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u''.__class__.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(basestring,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str().__class__.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(object,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basestring.__class__.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 chars 56 4 chars58\n"
     ]
    }
   ],
   "source": [
    "print(\"3 chars {} 4 chars{}\".format(size(u'abc'), size(u'abcd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 chars 40 4 chars41\n"
     ]
    }
   ],
   "source": [
    "print(\"3 chars {} 4 chars{}\".format(size('abc'), size('abcd')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the unicode function will convert the first argument to unicode. The default encoding is 'ascii', which cannot handle charcters with codes > 127."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'abcdef'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode('abcdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'abcdef'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode('abcdef'+chr(255), errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ꀀabc޴⟰\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 11)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = unichr(40960) + u'abc' + unichr(1972) + u'\\u27f0'\n",
    "print u\n",
    "len(u), len(u.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xea\\x80\\x80abc\\xde\\xb4\\xe2\\x9f\\xb0'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\ua000' in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-29840d2e0bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\ua000' in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "u.encode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&#40960;abc&#1972;&#10224;'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.encode('ascii', 'xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the unicode string, and encode it into utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utf8_version = u.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check the types of each of the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(unicode, str, '\\xea\\x80\\x80abc\\xde\\xb4')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(u), type(utf8_version), utf8_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the encoded version is an str, not a unicode. this is a string of bytes, not a string of unicode characters. Lets look at the length of these strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u), len(utf8_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be interesting. There were 5 characters in the unicode string, 2 NON ascii chars, and 3 ascii chars. When encoded, there are 8 chars. We still have the 3 ascii chars, but the other two chars take up 5 bytes. One is encoded into 2 bytes, the other into 3 bytes. This should give you an idea why unicode isn't compatible with str format.. but, someties they can be equivalent, if there were no charcters wiht a code point > 127.\n",
    "\n",
    "Next, lets decode the utf-8 version and compare it to the original.. of course we expect them to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u == utf8_version.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we might need to create unicode strings. It's quite easy. There are multiple ways to express a code string. You can use hex, octal, or two different types of unicode escape.\n",
    "\n",
    "\\xXX is a hex escape. \\x followed by 2 hex characters can be used to represent any character in the 0-255 range.\n",
    "\\oOOO is an octal escape. You can use that re represent characters from 0-01ff, or 511. Octal is hard to think in.\n",
    "\\uXXXX is unicode and can be followed by 4 hex digits. So, you can represent any 2-byte unicode character.\n",
    "\\UXXXXXXXX is followed by 8 hex digits, and can represent a 4 byte character. \n",
    "\n",
    "4 bytes is all that is needed to represent any character in any language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vowels = u'\\u1f00\\u1f10\\u1f30\\u1f40\\u1f50'\n",
    "math = u'\\u2234 \\u2260 \\u2297'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀἐἰὀὐ\n",
      "∴ ≠ ⊗\n"
     ]
    }
   ],
   "source": [
    "print vowels\n",
    "print math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have stored the 'greek' representation of vowels as a string.. sort if like 'aeiou'.\n",
    "Want to find some more unicode characters? Here is a chart http://unicode.org/charts/\n",
    "\n",
    "The following are some examples of 3 byte unicode code points. I had to try a few to find ones that would print.. these worked on my machine, but YMMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🈁 🉐 🈂\n"
     ]
    }
   ],
   "source": [
    "morebytes = u'\\U0001f201 \\U0001f250 \\U0001f202'\n",
    "print morebytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can encode all characters with these escape sequences, but that's not the best way. If you want to paste code and text that includes unicode code points, you need to make sure python will interpret the characters in the code file appropriately, that's why we use this:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "```\n",
    "\n",
    "We place that in our code file, and then we can use utf8 characters in our program file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unicode specification includes a database of information about code points. For each code point that’s defined, the information includes the character’s name, its category, the numeric value if applicable (Unicode has characters representing the Roman numerals and fractions such as one-third and four-fifths). There are also properties related to the code point’s use in bidirectional text and other display-related properties.\n",
    "\n",
    "The following program displays some information about several characters, and prints the numeric value of one particular character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n",
      "1 0bf2 No TAMIL NUMBER ONE THOUSAND\n",
      "2 0f84 Mn TIBETAN MARK HALANTA\n",
      "3 1770 Lo TAGBANWA LETTER SA\n",
      "4 33af So SQUARE RAD OVER S SQUARED\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "u = unichr(233) + unichr(0x0bf2) + unichr(3972) + unichr(6000) + unichr(13231)\n",
    "\n",
    "for i, c in enumerate(u):\n",
    "    print i, '%04x' % ord(c), unicodedata.category(c),\n",
    "    print unicodedata.name(c)\n",
    "\n",
    "# Get numeric value of second character\n",
    "print unicodedata.numeric(u[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category codes are abbreviations describing the nature of the character. These are grouped into categories such as “Letter”, “Number”, “Punctuation”, or “Symbol”, which in turn are broken up into subcategories. To take the codes from the above output, 'Ll' means ‘Letter, lowercase’, 'No' means “Number, other”, 'Mn' is “Mark, nonspacing”, and 'So' is “Symbol, other”. See <http://www.unicode.org/reports/tr44/#General_Category_Values> for a list of category codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Unicode Data\n",
    "\n",
    "This is where we usually get into trouble...the normal file open function reads data as 8 bit bytes, assuming ascii encoding. If the file is actually in utf-8 format, then the bytes must be decoded. I many cases, this isn't an issue, since a lot of strings are just ascii, but as soon as we get a unicode character in there, we are in trouble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getfilesystemencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.git', '.gitignore', '.gitignore~', '.idea', '.ipynb_checkpoints', 'BSU Scripts', 'configs', 'dstTools.iml', 'environments', 'gb', 'gitstats', 'hombin', 'jgraph', 'JiraAPI.ipynb', 'leadreports', 'liquidplanner_API.pdf', 'nodeinstall.sh', 'partsim', 'partsim_deploy', 'pngcrush-1.7.17', 'pngcrush-1.7.17.zip', 'projectFilesBackup', 'requirements_deffiles.txt', 'schematics_deploy', 'scripts', 'shell_functions.sh', 'shell_functions.sh~', 'symview', 'test', 'tmp', 'Unicode.ipynb', 'untitled folder', 'upgrade_pip.sh', 'www']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.listdir('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'.DS_Store', u'.git', u'.gitignore', u'.gitignore~', u'.idea', u'.ipynb_checkpoints', u'BSU Scripts', u'configs', u'dstTools.iml', u'environments', u'gb', u'gitstats', u'hombin', u'jgraph', u'JiraAPI.ipynb', u'leadreports', u'liquidplanner_API.pdf', u'nodeinstall.sh', u'partsim', u'partsim_deploy', u'pngcrush-1.7.17', u'pngcrush-1.7.17.zip', u'projectFilesBackup', u'requirements_deffiles.txt', u'schematics_deploy', u'scripts', u'shell_functions.sh', u'shell_functions.sh~', u'symview', u'test', u'tmp', u'Unicode.ipynb', u'untitled folder', u'upgrade_pip.sh', u'www']\n"
     ]
    }
   ],
   "source": [
    "print os.listdir(u'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-6586d7dacb7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mUTF8Writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUTF8Writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'café'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/bnpraid/Users/kutenai/Envs/dsttools/lib/python2.7/codecs.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\" Writes the object's contents encoded to self.stream.\n\u001b[1;32m    356\u001b[0m         \"\"\"\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import sys\n",
    "UTF8Writer = codecs.getwriter('utf8')\n",
    "sys.stdout = UTF8Writer(sys.stdout)\n",
    "print 'café'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'café'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/tmp/testfile.txt', 'w') as fp:\n",
    "    fp.write(u'café'.encode('utf-8'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "with codecs.open(u'/tmp/testfile.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        print type(line)\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named kitchen.text.converters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-84975ad52610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkitchen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_unicode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkitchen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi18n\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_translation_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named kitchen.text.converters"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "from kitchen.text.converters import getwriter, to_bytes, to_unicode\n",
    "from kitchen.i18n import get_translation_object\n",
    "\n",
    "encoding = locale.getpreferredencoding()\n",
    "Writer = getwriter(encoding)\n",
    "sys.stdout = Writer(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Peña\n",
      "La Pe�a\n",
      "La Peña\n"
     ]
    }
   ],
   "source": [
    "s = u'La Pe\\xf1a'\n",
    "print s\n",
    "print s.encode('latin-1')\n",
    "print s.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
